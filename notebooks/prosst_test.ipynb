{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from Bio import SeqIO\n",
    "from scipy.stats import spearmanr\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "prosst_path = \"/home/rcalef/sandbox/repos/magneton/magneton/external/ProSST\"\n",
    "sys.path.append(prosst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prosst.structure.get_sst_seq import SSTPredictor, init_shared_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_shared_pool(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load Model on cuda ----------\n",
      "MODEL: 5.90M parameters\n",
      "---------- Building Subgraphs ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "example_pdb = prosst_path + \"/example_data/p1.pdb\"\n",
    "\n",
    "#example_pdb = \"/weka/scratch/weka/kellislab/rcalef/data/pdb_alphafolddb/AF-A1RZJ9-F1-model_v4.pdb\"\n",
    "predictor = SSTPredictor(structure_vocab_size=2048) # can be 20, 128, 512, 1024, 2048, 4096\n",
    "result = predictor.predict_from_pdb(example_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0][\"2048_sst_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0][\"aa_seq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring example from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/rcalef/storage/om_storage/model_weights/ProSST-2048\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTOnlyMLMHead(\n",
       "  (predictions): ProSSTLMPredictionHead(\n",
       "    (transform): ProSSTPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (transform_act_fn): GELUActivation()\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=25, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.prosst.encoder.layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "residue_sequence = str(SeqIO.read(prosst_path + '/zero_shot/example_data/GRB2_HUMAN_Faure_2021.fasta', 'fasta').seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Building Subgraphs ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "structure_sequence = predictor.predict_from_pdb(prosst_path + \"/zero_shot/example_data/GRB2_HUMAN_Faure_2021.pdb\")[0]['2048_sst_seq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_sequence_offset = [i + 3 for i in structure_sequence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_res = tokenizer([residue_sequence], return_tensors='pt')\n",
    "input_ids = tokenized_res['input_ids']\n",
    "attention_mask = tokenized_res['attention_mask']\n",
    "structure_input_ids = torch.tensor([1, *structure_sequence_offset, 2], dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        ss_input_ids=structure_input_ids,\n",
    "        output_hidden_states=True,\n",
    "    )\n",
    "logits = torch.log_softmax(outputs.logits[:, 1:-1], dim=-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(prosst_path + \"/zero_shot/example_data/GRB2_HUMAN_Faure_2021.csv\")\n",
    "mutants = df['mutant'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "pred_scores = []\n",
    "for mutant in mutants:\n",
    "    mutant_score = 0\n",
    "    for sub_mutant in mutant.split(\":\"):\n",
    "        wt, idx, mt = sub_mutant[0], int(sub_mutant[1:-1]) - 1, sub_mutant[-1]\n",
    "        pred = logits[idx, vocab[mt]] - logits[idx, vocab[wt]]\n",
    "        mutant_score += pred.item()\n",
    "    pred_scores.append(mutant_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.7182950414920266, pvalue=0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(pred_scores, df['DMS_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2485, -0.1342, -0.0800,  ...,  0.3164,  0.1432,  0.0799],\n",
       "          [-0.0896, -0.1648,  0.4901,  ...,  0.1394,  0.0144,  0.1983],\n",
       "          [ 0.1657, -0.1281,  0.3248,  ..., -0.0207,  0.0780, -0.5081],\n",
       "          ...,\n",
       "          [ 0.2166,  0.0608,  0.2667,  ..., -0.0236,  0.2734,  0.4715],\n",
       "          [ 0.2006, -0.2071,  0.8953,  ..., -0.2292, -0.1639,  0.2802],\n",
       "          [-0.1214,  0.0263,  0.0887,  ...,  0.0862,  0.0719, -0.0068]]]),\n",
       " tensor([[[-2.5764e-03, -1.0332e-01,  4.5247e-02,  ..., -3.8302e-03,\n",
       "           -1.0434e-01, -1.3491e-02],\n",
       "          [ 1.0533e-01,  3.2962e-03,  4.6990e-02,  ...,  3.2873e-01,\n",
       "            2.7378e-01, -4.6533e-02],\n",
       "          [ 6.9737e-02, -9.1406e-02,  1.9271e-01,  ...,  1.2026e-01,\n",
       "           -1.9264e-01, -4.4676e-02],\n",
       "          ...,\n",
       "          [ 1.4992e-02,  2.1682e-02,  8.5999e-02,  ..., -5.0822e-02,\n",
       "            1.1033e-01, -8.3667e-02],\n",
       "          [ 6.6207e-02, -1.1911e-01,  9.3116e-02,  ..., -5.9162e-02,\n",
       "            1.3843e-01, -1.0879e-04],\n",
       "          [-7.9360e-02,  2.6117e-01, -2.4570e-01,  ...,  9.5050e-04,\n",
       "            3.0390e-01, -2.6163e-02]]]),\n",
       " tensor([[[-1.6533e-02, -1.9916e-02, -4.8254e-03,  ...,  7.3881e-03,\n",
       "           -9.4823e-02,  6.2221e-02],\n",
       "          [ 2.0672e-02, -1.1507e-02, -4.2997e-02,  ..., -7.0243e-02,\n",
       "            4.3596e-01,  1.5458e-01],\n",
       "          [ 1.2477e-01, -1.4210e-01, -7.6258e-02,  ...,  1.5672e-01,\n",
       "           -2.2409e-03,  2.8163e-02],\n",
       "          ...,\n",
       "          [-2.1129e-01,  8.8937e-02,  1.4857e-01,  ...,  7.3234e-02,\n",
       "           -2.5468e-02, -6.3140e-02],\n",
       "          [-5.5754e-02, -1.0673e-01,  2.7430e-02,  ...,  4.1163e-02,\n",
       "            7.0635e-02,  1.2176e-02],\n",
       "          [-5.9346e-03, -2.4387e-02, -1.5412e-04,  ..., -1.7266e-02,\n",
       "           -4.1714e-02,  9.4351e-02]]]),\n",
       " tensor([[[-0.0239, -0.0256, -0.0273,  ...,  0.0258, -0.0709, -0.0251],\n",
       "          [ 0.2281, -0.0815, -0.0458,  ...,  0.0803,  0.8046, -0.1605],\n",
       "          [ 0.2128, -0.1456, -0.0736,  ...,  0.2206,  0.2583, -0.0318],\n",
       "          ...,\n",
       "          [ 0.0600,  0.0275, -0.0760,  ..., -0.0454, -0.0501,  0.0181],\n",
       "          [-0.0964,  0.0738,  0.0087,  ..., -0.0215,  0.1886, -0.0278],\n",
       "          [-0.0354, -0.0009,  0.2053,  ..., -0.0696, -0.0094, -0.1284]]]),\n",
       " tensor([[[-0.0484,  0.0085, -0.0081,  ...,  0.0114, -0.0412, -0.0159],\n",
       "          [ 0.0250,  0.0388,  0.0262,  ..., -0.3020,  0.8581,  0.0097],\n",
       "          [-0.0123, -0.0328, -0.0812,  ..., -0.2065,  0.0286,  0.0780],\n",
       "          ...,\n",
       "          [-0.1533,  0.0758,  0.1375,  ...,  0.0494,  0.0973,  0.1536],\n",
       "          [-0.0799,  0.0210,  0.2837,  ...,  0.1094,  0.4614, -0.0413],\n",
       "          [-0.0119, -0.0207,  0.0074,  ..., -0.0705,  0.0548, -0.0150]]]),\n",
       " tensor([[[-9.8042e-03,  3.2169e-02, -9.0532e-04,  ...,  1.8621e-02,\n",
       "           -2.0229e-02, -2.3611e-02],\n",
       "          [-1.2799e-01, -4.3702e-02, -2.1428e-01,  ..., -3.6949e-01,\n",
       "            1.4558e+00,  1.6717e-01],\n",
       "          [ 2.2346e-02, -6.1918e-02,  3.2272e-02,  ..., -4.6054e-01,\n",
       "            2.8888e-01, -1.6348e-01],\n",
       "          ...,\n",
       "          [ 3.1219e-02,  4.7300e-01,  1.2317e-01,  ...,  4.2583e-01,\n",
       "            8.1162e-02, -1.1806e-01],\n",
       "          [ 2.7109e-01,  5.9643e-01,  5.0350e-01,  ...,  4.3256e-01,\n",
       "            3.8386e-01, -1.3423e-01],\n",
       "          [-9.3285e-03,  3.5671e-02, -5.2621e-03,  ...,  2.0790e-02,\n",
       "           -2.3704e-02, -2.3774e-02]]]),\n",
       " tensor([[[-9.9549e-03,  7.2242e-04, -1.2462e-02,  ..., -3.8893e-03,\n",
       "           -2.0136e-02, -3.8639e-03],\n",
       "          [ 2.7786e-01,  2.9195e-01, -2.1895e-01,  ..., -2.3510e-01,\n",
       "            1.6851e+00,  4.5370e-01],\n",
       "          [ 1.3843e-01,  3.9469e-01, -3.8076e-01,  ..., -2.7488e-01,\n",
       "            4.3372e-01, -4.0246e-01],\n",
       "          ...,\n",
       "          [-1.7025e-01,  4.7904e-01,  3.2634e-01,  ...,  3.9669e-01,\n",
       "           -2.2179e-01, -8.2647e-02],\n",
       "          [ 4.3343e-01,  3.3738e-01,  5.4207e-01,  ...,  1.0402e-01,\n",
       "            1.9960e-01,  6.1810e-02],\n",
       "          [-5.9949e-03,  1.9469e-03, -1.3921e-02,  ..., -4.0872e-03,\n",
       "           -2.3526e-02, -4.3386e-03]]]),\n",
       " tensor([[[ 1.5414e-03,  1.7014e-02, -7.5435e-03,  ...,  1.7728e-03,\n",
       "           -1.0564e-02,  3.2298e-03],\n",
       "          [-8.0332e-03,  3.2735e-01, -6.0343e-01,  ..., -4.2231e-01,\n",
       "            1.6570e+00,  2.1863e-01],\n",
       "          [ 4.4854e-01,  1.5127e-01, -3.9596e-01,  ..., -2.4334e-01,\n",
       "            3.3384e-01, -3.2683e-01],\n",
       "          ...,\n",
       "          [-2.0785e-01,  1.9896e-01, -8.0488e-02,  ...,  3.4692e-01,\n",
       "           -2.6881e-01,  1.9544e-01],\n",
       "          [ 2.8483e-01, -7.0322e-02,  2.0482e-01,  ..., -2.9799e-02,\n",
       "            1.8031e-01,  1.4350e-01],\n",
       "          [ 6.9535e-04,  1.0690e-02, -8.2101e-03,  ...,  1.4706e-03,\n",
       "           -9.2545e-03,  2.2872e-03]]]),\n",
       " tensor([[[ 0.0112,  0.0232, -0.0163,  ..., -0.0104, -0.0257, -0.0090],\n",
       "          [ 0.3050,  0.0735, -0.5370,  ...,  0.1396,  1.2720,  0.0482],\n",
       "          [ 0.2848, -0.5032,  0.1239,  ..., -0.5503,  0.0985, -0.4371],\n",
       "          ...,\n",
       "          [ 0.0059,  0.2113,  0.1748,  ...,  0.4490, -0.3147, -0.0481],\n",
       "          [ 0.0592, -0.1169,  0.3468,  ...,  0.3217,  0.1910,  0.1889],\n",
       "          [ 0.0060,  0.0240, -0.0171,  ..., -0.0129, -0.0294, -0.0085]]]),\n",
       " tensor([[[-1.3962e-02, -4.3622e-03, -8.4488e-03,  ...,  1.1362e-02,\n",
       "            4.8488e-03, -1.6890e-04],\n",
       "          [ 1.7156e-01, -1.6729e-01, -4.3618e-01,  ...,  6.6309e-02,\n",
       "            1.4052e+00,  2.5822e-02],\n",
       "          [-1.4505e-01, -5.1685e-01,  2.9974e-01,  ..., -2.0761e-01,\n",
       "            2.5350e-01, -1.4456e-01],\n",
       "          ...,\n",
       "          [ 2.1449e-01,  4.2496e-02,  4.6340e-01,  ...,  1.4181e-01,\n",
       "           -2.9650e-01, -2.1339e-01],\n",
       "          [ 4.8340e-01, -2.4552e-01,  1.7962e-01,  ..., -4.3277e-02,\n",
       "           -2.6823e-02,  1.6487e-01],\n",
       "          [-1.0540e-02, -1.0042e-03, -1.0846e-02,  ...,  9.1158e-03,\n",
       "           -1.4244e-03, -2.3796e-03]]]),\n",
       " tensor([[[-0.0133,  0.0116, -0.0160,  ...,  0.0158, -0.0192, -0.0187],\n",
       "          [ 0.5118, -0.1955, -0.0145,  ..., -0.0217,  1.4634,  0.0192],\n",
       "          [-0.0831, -0.5347,  0.6454,  ...,  0.1703,  0.6980,  0.2058],\n",
       "          ...,\n",
       "          [ 0.2346, -0.5258,  0.3855,  ..., -0.0377,  0.0693, -0.3596],\n",
       "          [ 0.8025, -0.5336,  0.2731,  ...,  0.3158, -0.0780,  0.2466],\n",
       "          [-0.0122,  0.0106, -0.0138,  ...,  0.0174, -0.0238, -0.0182]]]),\n",
       " tensor([[[ 0.0024,  0.0164, -0.0166,  ...,  0.0142, -0.0183, -0.0223],\n",
       "          [ 0.3714,  0.2274, -0.0688,  ...,  0.0242,  1.2102, -0.1503],\n",
       "          [-0.4219,  0.3590,  0.6376,  ...,  0.3101,  0.5137,  0.0511],\n",
       "          ...,\n",
       "          [ 0.4299, -0.4576,  0.3601,  ...,  0.1260, -0.1707, -0.2290],\n",
       "          [ 0.6736, -0.5054,  0.4929,  ...,  0.2211, -0.2304,  0.0976],\n",
       "          [ 0.0021,  0.0130, -0.0137,  ...,  0.0148, -0.0188, -0.0225]]]),\n",
       " tensor([[[-0.2167,  0.1375,  0.1799,  ..., -0.5005,  0.2330,  0.0273],\n",
       "          [ 0.2498,  0.1308,  0.3468,  ...,  0.0229,  0.7961,  0.2188],\n",
       "          [-0.3427,  0.1548,  0.2143,  ..., -0.1019,  0.4803,  0.3657],\n",
       "          ...,\n",
       "          [ 0.1997, -0.2016,  0.0561,  ..., -0.2137, -0.0130, -0.0561],\n",
       "          [ 0.3035, -0.1912,  0.2098,  ...,  0.0752,  0.0837,  0.1408],\n",
       "          [-0.1364, -0.4477, -0.4392,  ..., -0.6336,  0.5690,  0.1328]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1, 13, 17,  3,  6, 12, 15, 11, 17, 20, 20, 20,  6, 17,  8,  3, 12, 16,\n",
       "          7, 12, 15,  6, 20, 12, 17,  6, 12,  8,  4, 18, 11, 19, 20, 20, 20, 19,\n",
       "          5, 18,  8, 20, 21, 18, 20, 20,  8, 18, 20, 20,  6,  8,  3, 12, 17,  8,\n",
       "         12,  3, 22,  6, 20, 20, 22, 10,  6,  3,  3,  5, 14, 18, 14, 20,  6, 17,\n",
       "          3, 17, 18,  3,  3, 17, 17, 20,  6,  3,  4,  3, 20,  3,  8, 12,  8,  8,\n",
       "          8, 17, 15, 20,  5, 20,  3, 11, 22,  3,  3,  7, 13,  6,  8, 12, 15,  7,\n",
       "         20, 18, 20, 15, 19,  3, 10, 18,  9,  5,  8,  7,  3, 18, 15, 10, 20,  3,\n",
       "         12, 11,  5, 15,  6,  8, 14, 15, 12, 18, 10,  7, 19, 17, 15, 15,  3,  3,\n",
       "         20, 12, 20,  5, 12,  3, 20, 20, 18, 17,  3, 15, 17, 17, 12, 12,  3, 18,\n",
       "          8, 20,  8,  5, 10, 20,  8, 11, 20, 19, 18, 20,  3,  5,  3, 17, 12,  3,\n",
       "         16, 17, 12, 19,  8,  6,  6, 20, 15,  6, 20,  3, 12, 17, 13,  3,  6, 19,\n",
       "          3,  3, 17, 13, 20, 12,  5,  6, 20,  5,  6, 10,  3, 18, 21, 19,  6, 17,\n",
       "          8, 20,  8, 20, 12,  3, 16,  3,  8, 12, 12,  3,  8, 13,  3, 13,  3, 20,\n",
       "          3,  8, 18, 18, 17, 15,  4, 18,  8, 18,  6,  9, 12,  7, 18,  9, 18, 12,\n",
       "          5, 11, 22, 20, 15, 21, 11, 11, 18, 12,  9,  8,  6, 16, 20,  8, 20,  8,\n",
       "          3, 10, 10,  3, 18, 22, 12,  9,  8,  7, 14, 21, 17, 20, 10, 17,  5,  3,\n",
       "         12,  3, 11, 20,  8,  3, 15, 19, 19, 20,  6,  8, 12,  8, 20, 19,  8,  6,\n",
       "          5,  3, 20, 17,  3, 12, 12, 11,  3, 17,  6, 12, 17, 11, 17,  7, 19, 10,\n",
       "         12,  5, 20, 20,  6, 12, 14,  6,  8, 12,  3, 21, 11, 20, 12, 17,  6, 19,\n",
       "          8, 20,  3, 15, 19,  3,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks = tokenizer(result[0][\"aa_seq\"], return_tensors=\"pt\")\n",
    "aa_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 349])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([347])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_toks = torch.tensor(result[0][\"2048_sst_seq\"])\n",
    "ss_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (list, Tensor, list), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss_toks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: cat() received an invalid combination of arguments - got (list, Tensor, list), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "torch.cat([1], ss_toks, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 347])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-18.3368, -12.2662, -13.9507,  ...,   0.8657, -15.6547, -18.3795],\n",
       "         [-18.8052, -12.7068, -15.0800,  ...,   0.6976, -16.0266, -18.8201],\n",
       "         [-18.6050, -12.5979, -14.4972,  ...,   0.2606, -15.8135, -18.6339],\n",
       "         ...,\n",
       "         [-18.6463, -12.9135, -14.2035,  ...,   0.7077, -15.9107, -18.6853],\n",
       "         [-18.7029, -13.0057, -14.9421,  ...,   0.2711, -16.3094, -18.7389],\n",
       "         [-19.0306, -13.0453, -15.0684,  ...,   0.3415, -16.1042, -19.0603]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def forward(\n",
    "#     self,\n",
    "#     input_ids: Optional[torch.Tensor] = None,\n",
    "#     ss_input_ids: Optional[torch.Tensor] = None,\n",
    "#     attention_mask: Optional[torch.Tensor] = None,\n",
    "#     token_type_ids: Optional[torch.Tensor] = None,\n",
    "#     position_ids: Optional[torch.Tensor] = None,\n",
    "#     inputs_embeds: Optional[torch.Tensor] = None,\n",
    "#     labels: Optional[torch.Tensor] = None,\n",
    "#     output_attentions: Optional[bool] = None,\n",
    "#     output_hidden_states: Optional[bool] = None,\n",
    "#     return_dict: Optional[bool] = None,\n",
    "# ) -> Union[Tuple, MaskedLMOutput]:\n",
    "with torch.inference_mode():\n",
    "    out = model(\n",
    "        input_ids=aa_toks[\"input_ids\"],\n",
    "        ss_input_ids=ss_toks,\n",
    "        attention_mask=aa_toks[\"attention_mask\"],\n",
    "    )\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2023.09.6 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from magneton.config import (\n",
    "    DataConfig,\n",
    "    EmbeddingConfig,\n",
    "    ModelConfig,\n",
    "    TrainingConfig,\n",
    "    PipelineConfig,\n",
    ")\n",
    "from magneton.data import MagnetonDataModule\n",
    "from magneton.embedders.prosst_embedder import ProSSTConfig, ProSSTEmbedder\n",
    "from magneton.training.embedding_mlp import EmbeddingMLP, MultitaskEmbeddingMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpro_path = \"/weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/\"\n",
    "fasta_path = \"/weka/scratch/weka/kellislab/rcalef/data/uniprot/uniprot_sprot.fasta.gz\"\n",
    "labels_path = \"/weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/label_sets/selected_subset\"\n",
    "pickle_path = os.path.join(interpro_path, \"swissprot\", \"sharded_swissprot\", \"with_ss\", \"debug_datasets\")\n",
    "#pickle_path = os.path.join(interpro_path, \"swissprot\", \"sharded_swissprot\", \"with_ss\", \"dataset_splits\", \"seq_splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/rcalef/storage/om_storage/model_weights/ProSST-2048\"\n",
    "\n",
    "data_config = DataConfig(\n",
    "    data_dir=pickle_path,\n",
    "    prefix=\"swissprot.with_ss\",\n",
    "    fasta_path=fasta_path,\n",
    "    labels_path=labels_path,\n",
    "    substruct_types=[\"Domain\"],\n",
    "    collapse_labels=True,\n",
    "    struct_template=\"/weka/scratch/weka/kellislab/rcalef/data/pdb_alphafolddb/AF-%s-F1-model_v4.pdb\",\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MagnetonDataModule(\n",
    "    data_config=data_config,\n",
    "    model_type=\"prosst\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.42s/it]\n",
      "INFO:magneton.data.model_specific.prosst:ProSST tokens file found at: /weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/swissprot/sharded_swissprot/with_ss/debug_datasets/prosst_toks.tsv.bz2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:30:03   ProSST tokens file found at: /weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/swissprot/sharded_swissprot/with_ss/debug_datasets/prosst_toks.tsv.bz2\n",
      "/home/rcalef/storage/om_storage/model_weights/ProSST-2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:magneton.data.model_specific.prosst:read ProSST structure tokens for 132347 proteins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:30:43   read ProSST structure tokens for 132347 proteins\n"
     ]
    }
   ],
   "source": [
    "loader = module.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTBatch(protein_ids=['A0A024FA41', 'A0A059J0G5'], lengths=[365, 1567], seqs=None, substructures=[[LabeledSubstructure(ranges=[tensor([189, 335])], label=421, element_type='Domain')], [LabeledSubstructure(ranges=[tensor([525, 742]), tensor([1212, 1420])], label=551, element_type='Domain'), LabeledSubstructure(ranges=[tensor([ 95, 175])], label=735, element_type='Domain'), LabeledSubstructure(ranges=[tensor([167, 432]), tensor([ 891, 1134])], label=282, element_type='Domain')]], structure_list=None, prot_mask=None, labels=None, tokenized_seq=tensor([[ 1, 13, 15,  ...,  0,  0,  0],\n",
       "        [ 1, 13,  3,  ..., 10, 22,  2]]), tokenized_struct=tensor([[   1, 1233, 1233,  ...,    0,    0,    0],\n",
       "        [   1,  943,  943,  ..., 1060, 1136,    2]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_type=\"embedding_mlp\",\n",
    "    model_params={\n",
    "        \"hidden_dims\": [256, 256],\n",
    "        \"dropout_rate\": 0.1,\n",
    "    },\n",
    "    frozen_embedder=False,\n",
    ")\n",
    "prosst_config = ProSSTConfig(\n",
    "    weights_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = ProSSTEmbedder(prosst_config, frozen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedder.to(device)\n",
    "batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = embedder.embed_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5074e-02,  2.0554e-02,  2.9464e-03,  ...,  1.3994e-02,\n",
       "           4.9377e-02, -1.4424e-02],\n",
       "         [ 1.3344e-02,  7.8973e-03, -5.8249e-03,  ...,  9.2792e-03,\n",
       "          -2.6190e-02, -1.2555e-03],\n",
       "         [ 6.4270e-03,  1.0599e-02, -7.7542e-03,  ..., -1.3719e-03,\n",
       "          -2.4192e-02, -1.6272e-02],\n",
       "         ...,\n",
       "         [-4.8919e-03,  5.6617e-03,  1.3259e-03,  ...,  1.7139e-03,\n",
       "           7.8884e-03,  5.8250e-03],\n",
       "         [-4.8919e-03,  5.6617e-03,  1.3259e-03,  ...,  1.7139e-03,\n",
       "           7.8884e-03,  5.8250e-03],\n",
       "         [-4.8919e-03,  5.6617e-03,  1.3259e-03,  ...,  1.7139e-03,\n",
       "           7.8884e-03,  5.8250e-03]],\n",
       "\n",
       "        [[ 4.1353e-02,  2.0393e-02,  2.4705e-02,  ...,  4.9594e-03,\n",
       "           2.2046e-02,  3.6619e-03],\n",
       "         [ 1.7102e-02,  4.9413e-03,  1.4392e-03,  ..., -4.4777e-03,\n",
       "          -3.6532e-02, -1.0120e-02],\n",
       "         [-2.2535e-03,  1.4751e-03, -1.0967e-02,  ..., -1.0333e-02,\n",
       "           4.5706e-05, -1.5181e-02],\n",
       "         ...,\n",
       "         [ 2.9947e-03, -1.8542e-02,  7.0729e-03,  ..., -5.7440e-03,\n",
       "           2.8937e-02, -3.2850e-04],\n",
       "         [-6.2486e-04, -7.1609e-03,  4.1035e-03,  ..., -2.1146e-02,\n",
       "           9.4728e-03,  1.0884e-02],\n",
       "         [ 6.8692e-03, -2.7256e-03, -7.2865e-03,  ..., -6.0568e-02,\n",
       "           2.4772e-02,  2.6335e-02]]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, p in embedder.named_parameters():\n",
    "    if p.requires_grad and p.grad is None:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa2pos', 'pos2aa', 'aa2ss', 'ss2aa']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.prosst.encoder.layer[0].attention.self.pos_att_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTModel(\n",
       "  (embeddings): ProSSTEmbeddings(\n",
       "    (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "    (ss_embeddings): Embedding(2051, 768)\n",
       "    (ss_layer_norm): ProSSTLayerNorm()\n",
       "    (LayerNorm): ProSSTLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): ProSSTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ProSSTLayer(\n",
       "        (attention): ProSSTAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ProSSTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ProSSTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ProSSTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): ProSSTLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(2048, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.prosst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0365, -0.0922, -0.0679,  ...,  0.0392,  0.1228,  0.0718],\n",
       "        [ 0.0143, -0.0194, -0.0404,  ..., -0.0288, -0.0470,  0.0308],\n",
       "        [-0.0961, -0.0490, -0.0238,  ..., -0.0414, -0.0932,  0.1191],\n",
       "        ...,\n",
       "        [-0.0211, -0.0622,  0.0514,  ..., -0.0565,  0.0298,  0.0812],\n",
       "        [ 0.0134, -0.0049, -0.0624,  ...,  0.0704, -0.0666, -0.0145],\n",
       "        [ 0.0245, -0.0542, -0.0725,  ..., -0.0272,  0.0313,  0.0244]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.prosst.encoder.layer[10].attention.output.dense.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.get_output_embeddings().in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 778])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.tokenized_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1163])\n",
      "torch.Size([2, 1163])\n",
      "torch.Size([2, 1163])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0127,  0.5458, -0.2287,  ..., -0.0958, -0.0664,  0.5374],\n",
       "         [ 0.2572,  0.0957,  0.1295,  ..., -0.0222,  0.4835, -0.0405],\n",
       "         [ 0.3038,  0.0396,  0.0052,  ..., -0.1692, -0.0866,  0.4359],\n",
       "         ...,\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099],\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099],\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099]],\n",
       "\n",
       "        [[ 0.3875, -0.2288, -0.1128,  ..., -0.1080, -0.0196,  0.1385],\n",
       "         [ 0.3325,  0.4462,  0.2209,  ..., -0.2696,  0.6936,  0.0857],\n",
       "         [-0.1536,  0.0761,  0.1590,  ..., -0.3747, -0.2730, -0.0158],\n",
       "         ...,\n",
       "         [ 0.2958, -0.5699,  0.3141,  ...,  0.0576,  0.1312,  0.0399],\n",
       "         [ 0.4738, -0.1931,  0.2375,  ...,  0.0573,  0.0022,  0.3500],\n",
       "         [ 0.9418, -0.3425,  0.0878,  ..., -0.4024, -0.3270,  0.1994]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = embedder.embed_batch(batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163, 768])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "got = F.normalize(out.hidden_states[12], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "check = got.norm(dim=-1)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTModel(\n",
       "  (embeddings): ProSSTEmbeddings(\n",
       "    (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "    (ss_embeddings): Embedding(2051, 768)\n",
       "    (ss_layer_norm): ProSSTLayerNorm()\n",
       "    (LayerNorm): ProSSTLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): ProSSTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ProSSTLayer(\n",
       "        (attention): ProSSTAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ProSSTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ProSSTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ProSSTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): ProSSTLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(2048, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3121, 0.3089, 0.3078, 0.3285, 0.2895, 0.2951, 0.3388, 0.2945, 0.2910,\n",
       "        0.3344, 0.3081, 0.3292, 0.3346, 0.2586, 0.2828, 0.2632, 0.2735, 0.2689,\n",
       "        0.3046, 0.3257], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.encoder_model.W_v[0].scalar_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating esmc embedder ===\n",
      "EmbeddingConfig(_target_='magneton.config.EmbeddingConfig',\n",
      "                model='esmc',\n",
      "                batch_size=32,\n",
      "                model_params={'mask_prob': 0.15,\n",
      "                              'max_seq_length': 2048,\n",
      "                              'model_size': '600m',\n",
      "                              'rep_layer': 33,\n",
      "                              'use_flash_attn': True,\n",
      "                              'weights_path': '/weka/scratch/weka/kellislab/rcalef/model_weights/esmc-600m-2024-12'})\n",
      "Config parameters: None\n"
     ]
    }
   ],
   "source": [
    "pipeline_config = PipelineConfig(\n",
    "    data=data_config,\n",
    "    model=model_config,\n",
    "    training=train_config,\n",
    "    embedding=EmbeddingConfig(\n",
    "        model=\"esmc\",\n",
    "        model_params=esmc_config.__dict__,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Train model\n",
    "if data_config.collapse_labels:\n",
    "    mlp = EmbeddingMLP(\n",
    "        config=pipeline_config,\n",
    "        num_classes=num_labels,\n",
    "    )\n",
    "else:\n",
    "    mlp = MultitaskEmbeddingMLP(\n",
    "        config=pipeline_config,\n",
    "        num_classes=num_labels,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
