{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "prosst_path = \"/home/rcalef/sandbox/repos/external/ProSST\"\n",
    "sys.path.append(prosst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prosst.structure.get_sst_seq import SSTPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load Model on cuda ----------\n",
      "MODEL: 5.90M parameters\n",
      "---------- Building Subgraphs ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.09s/it]\n"
     ]
    }
   ],
   "source": [
    "example_pdb = \"/weka/scratch/weka/kellislab/rcalef/data/pdb_alphafolddb/AF-A1RZJ9-F1-model_v4.pdb\"\n",
    "predictor = SSTPredictor(structure_vocab_size=2048) # can be 20, 128, 512, 1024, 2048, 4096\n",
    "result = predictor.predict_from_pdb(example_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'AF-A1RZJ9-F1-model_v4.pdb',\n",
       " 'aa_seq': 'MRAELPKRVVVERGALQFLPEVLRELGCSKTVVVTDSGVWSVVGSVVEGALRGLAYEVVYIEAADNSNVERARSAARRVEACAVAGLGGGRPVDVAKYAAFMEGLPFVSVPTAISHDGFASPIVALKDPEGNPLSIFTRPPAAVLVDLAVVSRAPRRLLASGVGDIVGKVTSVADARLAQRLTGEEVPEVALRMAETAARMVLDEVDEIASWTERGVGVLAQAGLLAGMAMAVAGSSRPCSGSEHLFSHSLDKYVPWKKSLHGEQVGVGAIIASYLHGFNWRVIRDALAKVGAPTTVEGLGVTGEDAVRALLKARELRKRFTILDVVELNEGLAWKVLRETGVAPTA',\n",
       " '2048_sst_seq': [1534,\n",
       "  1560,\n",
       "  146,\n",
       "  1590,\n",
       "  466,\n",
       "  973,\n",
       "  1423,\n",
       "  246,\n",
       "  314,\n",
       "  1155,\n",
       "  565,\n",
       "  1683,\n",
       "  352,\n",
       "  1348,\n",
       "  336,\n",
       "  196,\n",
       "  699,\n",
       "  913,\n",
       "  2037,\n",
       "  1282,\n",
       "  169,\n",
       "  235,\n",
       "  259,\n",
       "  937,\n",
       "  1304,\n",
       "  235,\n",
       "  388,\n",
       "  1612,\n",
       "  1232,\n",
       "  157,\n",
       "  1751,\n",
       "  1417,\n",
       "  1393,\n",
       "  269,\n",
       "  8,\n",
       "  1336,\n",
       "  646,\n",
       "  397,\n",
       "  83,\n",
       "  397,\n",
       "  64,\n",
       "  967,\n",
       "  1960,\n",
       "  624,\n",
       "  881,\n",
       "  513,\n",
       "  174,\n",
       "  1207,\n",
       "  75,\n",
       "  174,\n",
       "  1380,\n",
       "  1176,\n",
       "  510,\n",
       "  727,\n",
       "  1359,\n",
       "  774,\n",
       "  2002,\n",
       "  774,\n",
       "  1089,\n",
       "  1185,\n",
       "  1838,\n",
       "  505,\n",
       "  372,\n",
       "  1838,\n",
       "  372,\n",
       "  1687,\n",
       "  750,\n",
       "  573,\n",
       "  1339,\n",
       "  1739,\n",
       "  1339,\n",
       "  2037,\n",
       "  1663,\n",
       "  1691,\n",
       "  561,\n",
       "  365,\n",
       "  1938,\n",
       "  2000,\n",
       "  938,\n",
       "  190,\n",
       "  107,\n",
       "  727,\n",
       "  554,\n",
       "  554,\n",
       "  1417,\n",
       "  1089,\n",
       "  662,\n",
       "  78,\n",
       "  78,\n",
       "  541,\n",
       "  1232,\n",
       "  1232,\n",
       "  1232,\n",
       "  1236,\n",
       "  432,\n",
       "  442,\n",
       "  1545,\n",
       "  247,\n",
       "  562,\n",
       "  621,\n",
       "  972,\n",
       "  1328,\n",
       "  1380,\n",
       "  1908,\n",
       "  1279,\n",
       "  107,\n",
       "  107,\n",
       "  1417,\n",
       "  554,\n",
       "  1417,\n",
       "  78,\n",
       "  1851,\n",
       "  541,\n",
       "  489,\n",
       "  116,\n",
       "  661,\n",
       "  661,\n",
       "  1545,\n",
       "  1232,\n",
       "  1612,\n",
       "  773,\n",
       "  228,\n",
       "  126,\n",
       "  1882,\n",
       "  213,\n",
       "  213,\n",
       "  1255,\n",
       "  178,\n",
       "  1558,\n",
       "  598,\n",
       "  1511,\n",
       "  1243,\n",
       "  1034,\n",
       "  1915,\n",
       "  290,\n",
       "  1200,\n",
       "  96,\n",
       "  308,\n",
       "  922,\n",
       "  1204,\n",
       "  785,\n",
       "  246,\n",
       "  1096,\n",
       "  1702,\n",
       "  1244,\n",
       "  78,\n",
       "  196,\n",
       "  1837,\n",
       "  1491,\n",
       "  1533,\n",
       "  1545,\n",
       "  71,\n",
       "  787,\n",
       "  1629,\n",
       "  1571,\n",
       "  116,\n",
       "  787,\n",
       "  116,\n",
       "  987,\n",
       "  987,\n",
       "  661,\n",
       "  987,\n",
       "  383,\n",
       "  383,\n",
       "  383,\n",
       "  1513,\n",
       "  1513,\n",
       "  383,\n",
       "  383,\n",
       "  261,\n",
       "  1102,\n",
       "  1102,\n",
       "  1400,\n",
       "  1400,\n",
       "  277,\n",
       "  1277,\n",
       "  531,\n",
       "  1938,\n",
       "  1206,\n",
       "  388,\n",
       "  1731,\n",
       "  1736,\n",
       "  1736,\n",
       "  1552,\n",
       "  325,\n",
       "  1354,\n",
       "  828,\n",
       "  1692,\n",
       "  1400,\n",
       "  663,\n",
       "  2001,\n",
       "  182,\n",
       "  292,\n",
       "  205,\n",
       "  1572,\n",
       "  477,\n",
       "  995,\n",
       "  1435,\n",
       "  1572,\n",
       "  1520,\n",
       "  1520,\n",
       "  292,\n",
       "  1520,\n",
       "  346,\n",
       "  1520,\n",
       "  1721,\n",
       "  59,\n",
       "  346,\n",
       "  1721,\n",
       "  667,\n",
       "  1566,\n",
       "  1097,\n",
       "  1691,\n",
       "  1339,\n",
       "  1017,\n",
       "  1024,\n",
       "  1140,\n",
       "  27,\n",
       "  72,\n",
       "  1435,\n",
       "  1549,\n",
       "  39,\n",
       "  39,\n",
       "  383,\n",
       "  1135,\n",
       "  1435,\n",
       "  383,\n",
       "  661,\n",
       "  1991,\n",
       "  1005,\n",
       "  1991,\n",
       "  55,\n",
       "  223,\n",
       "  1366,\n",
       "  329,\n",
       "  932,\n",
       "  932,\n",
       "  787,\n",
       "  2001,\n",
       "  1845,\n",
       "  987,\n",
       "  1951,\n",
       "  1102,\n",
       "  408,\n",
       "  408,\n",
       "  960,\n",
       "  925,\n",
       "  2004,\n",
       "  787,\n",
       "  72,\n",
       "  27,\n",
       "  538,\n",
       "  24,\n",
       "  703,\n",
       "  828,\n",
       "  1479,\n",
       "  1176,\n",
       "  184,\n",
       "  1220,\n",
       "  1601,\n",
       "  1991,\n",
       "  661,\n",
       "  987,\n",
       "  987,\n",
       "  987,\n",
       "  1005,\n",
       "  477,\n",
       "  383,\n",
       "  408,\n",
       "  2004,\n",
       "  1435,\n",
       "  39,\n",
       "  408,\n",
       "  72,\n",
       "  72,\n",
       "  1073,\n",
       "  1928,\n",
       "  1325,\n",
       "  412,\n",
       "  608,\n",
       "  412,\n",
       "  1568,\n",
       "  1017,\n",
       "  1572,\n",
       "  1600,\n",
       "  1281,\n",
       "  477,\n",
       "  383,\n",
       "  323,\n",
       "  1721,\n",
       "  1097,\n",
       "  1518,\n",
       "  182,\n",
       "  661,\n",
       "  1077,\n",
       "  17,\n",
       "  1445,\n",
       "  796,\n",
       "  1533,\n",
       "  1157,\n",
       "  1127,\n",
       "  1682,\n",
       "  147,\n",
       "  1425,\n",
       "  277,\n",
       "  1815,\n",
       "  1005,\n",
       "  625,\n",
       "  2004,\n",
       "  925,\n",
       "  39,\n",
       "  1518,\n",
       "  642,\n",
       "  87,\n",
       "  1051,\n",
       "  1577,\n",
       "  2030,\n",
       "  1338,\n",
       "  478,\n",
       "  618,\n",
       "  1682,\n",
       "  337,\n",
       "  1384,\n",
       "  1961,\n",
       "  1582,\n",
       "  16,\n",
       "  1010,\n",
       "  1342,\n",
       "  323,\n",
       "  631,\n",
       "  355,\n",
       "  1639,\n",
       "  631,\n",
       "  706,\n",
       "  54,\n",
       "  355,\n",
       "  1187,\n",
       "  833,\n",
       "  71,\n",
       "  1346,\n",
       "  1005,\n",
       "  353,\n",
       "  353,\n",
       "  1524,\n",
       "  1019,\n",
       "  1337,\n",
       "  1969]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0][\"2048_sst_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0][\"aa_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/rcalef/storage/om_storage/model_weights/ProSST-2048\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTForMaskedLM(\n",
       "  (prosst): ProSSTModel(\n",
       "    (embeddings): ProSSTEmbeddings(\n",
       "      (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "      (ss_embeddings): Embedding(2051, 768)\n",
       "      (ss_layer_norm): ProSSTLayerNorm()\n",
       "      (LayerNorm): ProSSTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ProSSTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ProSSTLayer(\n",
       "          (attention): ProSSTAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProSSTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): ProSSTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProSSTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ProSSTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(2048, 768)\n",
       "    )\n",
       "  )\n",
       "  (cls): ProSSTOnlyMLMHead(\n",
       "    (predictions): ProSSTLMPredictionHead(\n",
       "      (transform): ProSSTPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=25, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmTokenizer(name_or_path='/home/rcalef/storage/om_storage/model_weights/ProSST-2048', vocab_size=25, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t23: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t24: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1, 13, 17,  3,  6, 12, 15, 11, 17, 20, 20, 20,  6, 17,  8,  3, 12, 16,\n",
       "          7, 12, 15,  6, 20, 12, 17,  6, 12,  8,  4, 18, 11, 19, 20, 20, 20, 19,\n",
       "          5, 18,  8, 20, 21, 18, 20, 20,  8, 18, 20, 20,  6,  8,  3, 12, 17,  8,\n",
       "         12,  3, 22,  6, 20, 20, 22, 10,  6,  3,  3,  5, 14, 18, 14, 20,  6, 17,\n",
       "          3, 17, 18,  3,  3, 17, 17, 20,  6,  3,  4,  3, 20,  3,  8, 12,  8,  8,\n",
       "          8, 17, 15, 20,  5, 20,  3, 11, 22,  3,  3,  7, 13,  6,  8, 12, 15,  7,\n",
       "         20, 18, 20, 15, 19,  3, 10, 18,  9,  5,  8,  7,  3, 18, 15, 10, 20,  3,\n",
       "         12, 11,  5, 15,  6,  8, 14, 15, 12, 18, 10,  7, 19, 17, 15, 15,  3,  3,\n",
       "         20, 12, 20,  5, 12,  3, 20, 20, 18, 17,  3, 15, 17, 17, 12, 12,  3, 18,\n",
       "          8, 20,  8,  5, 10, 20,  8, 11, 20, 19, 18, 20,  3,  5,  3, 17, 12,  3,\n",
       "         16, 17, 12, 19,  8,  6,  6, 20, 15,  6, 20,  3, 12, 17, 13,  3,  6, 19,\n",
       "          3,  3, 17, 13, 20, 12,  5,  6, 20,  5,  6, 10,  3, 18, 21, 19,  6, 17,\n",
       "          8, 20,  8, 20, 12,  3, 16,  3,  8, 12, 12,  3,  8, 13,  3, 13,  3, 20,\n",
       "          3,  8, 18, 18, 17, 15,  4, 18,  8, 18,  6,  9, 12,  7, 18,  9, 18, 12,\n",
       "          5, 11, 22, 20, 15, 21, 11, 11, 18, 12,  9,  8,  6, 16, 20,  8, 20,  8,\n",
       "          3, 10, 10,  3, 18, 22, 12,  9,  8,  7, 14, 21, 17, 20, 10, 17,  5,  3,\n",
       "         12,  3, 11, 20,  8,  3, 15, 19, 19, 20,  6,  8, 12,  8, 20, 19,  8,  6,\n",
       "          5,  3, 20, 17,  3, 12, 12, 11,  3, 17,  6, 12, 17, 11, 17,  7, 19, 10,\n",
       "         12,  5, 20, 20,  6, 12, 14,  6,  8, 12,  3, 21, 11, 20, 12, 17,  6, 19,\n",
       "          8, 20,  3, 15, 19,  3,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks = tokenizer(result[0][\"aa_seq\"], return_tensors=\"pt\")\n",
    "aa_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 349])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([347])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_toks = torch.tensor(result[0][\"2048_sst_seq\"])\n",
    "ss_toks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (list, Tensor, list), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss_toks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: cat() received an invalid combination of arguments - got (list, Tensor, list), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "torch.cat([1], ss_toks, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 347])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_toks[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-18.3368, -12.2662, -13.9507,  ...,   0.8657, -15.6547, -18.3795],\n",
       "         [-18.8052, -12.7068, -15.0800,  ...,   0.6976, -16.0266, -18.8201],\n",
       "         [-18.6050, -12.5979, -14.4972,  ...,   0.2606, -15.8135, -18.6339],\n",
       "         ...,\n",
       "         [-18.6463, -12.9135, -14.2035,  ...,   0.7077, -15.9107, -18.6853],\n",
       "         [-18.7029, -13.0057, -14.9421,  ...,   0.2711, -16.3094, -18.7389],\n",
       "         [-19.0306, -13.0453, -15.0684,  ...,   0.3415, -16.1042, -19.0603]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def forward(\n",
    "#     self,\n",
    "#     input_ids: Optional[torch.Tensor] = None,\n",
    "#     ss_input_ids: Optional[torch.Tensor] = None,\n",
    "#     attention_mask: Optional[torch.Tensor] = None,\n",
    "#     token_type_ids: Optional[torch.Tensor] = None,\n",
    "#     position_ids: Optional[torch.Tensor] = None,\n",
    "#     inputs_embeds: Optional[torch.Tensor] = None,\n",
    "#     labels: Optional[torch.Tensor] = None,\n",
    "#     output_attentions: Optional[bool] = None,\n",
    "#     output_hidden_states: Optional[bool] = None,\n",
    "#     return_dict: Optional[bool] = None,\n",
    "# ) -> Union[Tuple, MaskedLMOutput]:\n",
    "with torch.inference_mode():\n",
    "    out = model(\n",
    "        input_ids=aa_toks[\"input_ids\"],\n",
    "        ss_input_ids=ss_toks,\n",
    "        attention_mask=aa_toks[\"attention_mask\"],\n",
    "    )\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magneton.config import (\n",
    "    DataConfig,\n",
    "    EmbeddingConfig,\n",
    "    ModelConfig,\n",
    "    TrainingConfig,\n",
    "    PipelineConfig,\n",
    ")\n",
    "from magneton.embedders.prosst_embedder import ProSSTConfig, ProSSTDataModule, ProSSTEmbedder, move_prosst_inputs_to_device\n",
    "from magneton.embedders.esmc_embedder import ESMCConfig, ESMCDataModule, ESMCEmbedder\n",
    "from magneton.training.embedding_mlp import EmbeddingMLP, MultitaskEmbeddingMLP\n",
    "from magneton.types import InterProType\n",
    "from magneton.utils import move_inputs_to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpro_path = \"/weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/\"\n",
    "fasta_path = \"/weka/scratch/weka/kellislab/rcalef/data/uniprot/uniprot_sprot.fasta.gz\"\n",
    "labels_path = \"/weka/scratch/weka/kellislab/rcalef/data/interpro/103.0/label_sets/selected_subset\"\n",
    "pickle_path = os.path.join(interpro_path, \"swissprot\", \"sharded_swissprot\", \"with_ss\", \"debug_datasets\")\n",
    "#pickle_path = os.path.join(interpro_path, \"swissprot\", \"sharded_swissprot\", \"with_ss\", \"dataset_splits\", \"seq_splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/rcalef/storage/om_storage/model_weights/ProSST-2048\"\n",
    "\n",
    "data_config = DataConfig(\n",
    "    data_dir=pickle_path,\n",
    "    prefix=\"swissprot.with_ss\",\n",
    "    fasta_path=fasta_path,\n",
    "    labels_path=labels_path,\n",
    "    substruct_types=[\"Domain\"],\n",
    "    collapse_labels=True,\n",
    "    struct_template=\"/weka/scratch/weka/kellislab/rcalef/data/pdb_alphafolddb/AF-%s-F1-model_v4.pdb\",\n",
    "    model_specific_params={\n",
    "        \"model_path\": model_path,\n",
    "        \"num_threads\": 4,\n",
    "    }\n",
    ")\n",
    "\n",
    "train_config = TrainingConfig(\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ProSSTDataModule(\n",
    "    data_config=data_config,\n",
    "    train_config=train_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3715\n",
      "917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load = True\n",
    "if load:\n",
    "    data_loader = data_module.train_dataloader()\n",
    "    print(len(data_loader.dataset))\n",
    "    print(data_loader.dataset.substruct_parser.num_labels())\n",
    "    num_labels = data_loader.dataset.substruct_parser.num_labels()\n",
    "else:\n",
    "    num_labels = 917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 13, 13, 11,  7, 11, 15, 14, 16, 19, 17, 19, 22,  5, 17,  6,  8,  7,\n",
       "        11, 11, 17,  3,  3,  4, 12,  4,  7, 17, 18,  6, 16,  6,  5,  6, 20, 12,\n",
       "        12, 20, 18, 18, 18, 17, 22, 15,  5, 16, 21, 10, 20, 15,  8,  8,  8, 13,\n",
       "         6, 15,  6,  6,  6, 15,  8,  8,  3,  3, 20, 17,  6, 20, 22,  6,  6,  3,\n",
       "         8, 20, 11,  8, 11, 12,  8, 17, 12, 12,  8, 10,  7,  6, 16, 14, 16,  5,\n",
       "        17, 11,  9, 17, 19, 22, 20, 22, 20, 12, 19, 20, 19,  6, 10, 12,  6,  5,\n",
       "        21,  6,  5, 18, 20, 14, 10,  8, 17, 11, 17,  6, 21,  7, 11, 20,  6,  5,\n",
       "         3, 10, 11, 20, 12, 16,  4,  9, 11, 15, 20,  9,  3,  6, 22, 12,  6, 11,\n",
       "        12, 11, 12,  8,  4, 18, 15,  3, 14,  8, 14, 18, 19, 20, 15, 18, 12, 15,\n",
       "         5, 14, 14,  3, 12,  7, 20, 19,  3,  3, 16, 19, 18,  8, 12, 15, 18, 18,\n",
       "        20, 17,  2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.dataset[10].sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTBatch(substructures=[[LabeledSubstructure(ranges=[tensor([112, 272])], label=548, element_type='Domain'), LabeledSubstructure(ranges=[tensor([ 3, 65])], label=700, element_type='Domain'), LabeledSubstructure(ranges=[tensor([356, 445])], label=541, element_type='Domain')], [LabeledSubstructure(ranges=[tensor([793, 943])], label=178, element_type='Domain')]], prot_ids=['A0L3I7', 'A1CQA9'], batch_graphs=DataBatch(edge_index=[2, 216206], node_s=[23105, 20], node_v=[23105, 3, 3], edge_s=[216206, 32], edge_v=[216206, 1, 3], batch=[23105], ptr=[1640]), tokenized_seqs=tensor([[ 1, 13, 16,  ...,  0,  0,  0],\n",
       "        [ 1, 13,  3,  ..., 20, 20,  2]]), protein_lengths=[447, 1192])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_type=\"embedding_mlp\",\n",
    "    model_params={\n",
    "        \"hidden_dims\": [256, 256],\n",
    "        \"dropout_rate\": 0.1,\n",
    "    },\n",
    "    frozen_embedder=False,\n",
    ")\n",
    "prosst_config = ProSSTConfig(\n",
    "    weights_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = ProSSTEmbedder(prosst_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.get_output_embeddings().in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder.model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 778])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.tokenized_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1163])\n",
      "torch.Size([2, 1163])\n",
      "torch.Size([2, 1163])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0127,  0.5458, -0.2287,  ..., -0.0958, -0.0664,  0.5374],\n",
       "         [ 0.2572,  0.0957,  0.1295,  ..., -0.0222,  0.4835, -0.0405],\n",
       "         [ 0.3038,  0.0396,  0.0052,  ..., -0.1692, -0.0866,  0.4359],\n",
       "         ...,\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099],\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099],\n",
       "         [-0.0923,  0.1068,  0.0250,  ...,  0.0323,  0.1488,  0.1099]],\n",
       "\n",
       "        [[ 0.3875, -0.2288, -0.1128,  ..., -0.1080, -0.0196,  0.1385],\n",
       "         [ 0.3325,  0.4462,  0.2209,  ..., -0.2696,  0.6936,  0.0857],\n",
       "         [-0.1536,  0.0761,  0.1590,  ..., -0.3747, -0.2730, -0.0158],\n",
       "         ...,\n",
       "         [ 0.2958, -0.5699,  0.3141,  ...,  0.0576,  0.1312,  0.0399],\n",
       "         [ 0.4738, -0.1931,  0.2375,  ...,  0.0573,  0.0022,  0.3500],\n",
       "         [ 0.9418, -0.3425,  0.0878,  ..., -0.4024, -0.3270,  0.1994]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = embedder.embed_batch(batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163, 768])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "got = F.normalize(out.hidden_states[12], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "check = got.norm(dim=-1)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1163])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProSSTModel(\n",
       "  (embeddings): ProSSTEmbeddings(\n",
       "    (word_embeddings): Embedding(25, 768, padding_idx=0)\n",
       "    (ss_embeddings): Embedding(2051, 768)\n",
       "    (ss_layer_norm): ProSSTLayerNorm()\n",
       "    (LayerNorm): ProSSTLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): ProSSTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ProSSTLayer(\n",
       "        (attention): ProSSTAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (ss_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (ss_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): ProSSTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): ProSSTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ProSSTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ProSSTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): ProSSTLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(2048, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3121, 0.3089, 0.3078, 0.3285, 0.2895, 0.2951, 0.3388, 0.2945, 0.2910,\n",
       "        0.3344, 0.3081, 0.3292, 0.3346, 0.2586, 0.2828, 0.2632, 0.2735, 0.2689,\n",
       "        0.3046, 0.3257], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.encoder_model.W_v[0].scalar_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating esmc embedder ===\n",
      "EmbeddingConfig(_target_='magneton.config.EmbeddingConfig',\n",
      "                model='esmc',\n",
      "                batch_size=32,\n",
      "                model_params={'mask_prob': 0.15,\n",
      "                              'max_seq_length': 2048,\n",
      "                              'model_size': '600m',\n",
      "                              'rep_layer': 33,\n",
      "                              'use_flash_attn': True,\n",
      "                              'weights_path': '/weka/scratch/weka/kellislab/rcalef/model_weights/esmc-600m-2024-12'})\n",
      "Config parameters: None\n"
     ]
    }
   ],
   "source": [
    "pipeline_config = PipelineConfig(\n",
    "    data=data_config,\n",
    "    model=model_config,\n",
    "    training=train_config,\n",
    "    embedding=EmbeddingConfig(\n",
    "        model=\"esmc\",\n",
    "        model_params=esmc_config.__dict__,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Train model\n",
    "if data_config.collapse_labels:\n",
    "    mlp = EmbeddingMLP(\n",
    "        config=pipeline_config,\n",
    "        num_classes=num_labels,\n",
    "    )\n",
    "else:\n",
    "    mlp = MultitaskEmbeddingMLP(\n",
    "        config=pipeline_config,\n",
    "        num_classes=num_labels,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
