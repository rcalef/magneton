defaults:
  - base_pipeline
  #- data: debug
  - data: interpro103_swissprot
  - embedding: gearnet
  - evaluate: go
  - _self_
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

run_id: esmc_embed_conserved_site
output_dir: "/weka/scratch/weka/kellislab/rcalef/projects/magneton/experiments/esmc_test"
test_dir: "/net/vast-storage/scratch/vast/kellislab/artliang/magneton/magneton/tests/esmc"
model:
  model_type: "mlp"
  model_params:
    hidden_dims: [256, 256, 256]
    dropout_rate: 0.1
  # checkpoint: "/weka/scratch/weka/kellislab/rcalef/projects/magneton/experiments/esmc/checkpoints_esmc_embed_domain/epoch=3-val_f1=0.97.ckpt"
  # checkpoint: "/weka/scratch/weka/kellislab/rcalef/projects/magneton/experiments/esmc/checkpoints_esmc_embed_superfam/epoch=2-val_f1=0.92.ckpt"
  checkpoint: "/weka/scratch/weka/kellislab/rcalef/projects/magneton/experiments/esmc/checkpoints_esmc_embed_conserved_sites/epoch=2-val_f1=0.96.ckpt"

training:
  max_epochs: 5
  accelerator: gpu
  devices: auto
  learning_rate: 0.001
  weight_decay: 0.01
  additional_training_kwargs:
    limit_val_batches: 0.2
    val_check_interval: 0.25

hydra:
  run:
    dir: ${output_dir}
